{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pneumonia-diagnosis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPEYYEuzMNd1csHH7BK682r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stavrospanakakis/pneumonia-diagnosis/blob/master/pneumonia_diagnosis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkAEKUoES551",
        "colab_type": "text"
      },
      "source": [
        "# Requirements\n",
        "- Create a kaggle acount\n",
        "\n",
        "- Go to https://www.kaggle.com/USERNAME/account\n",
        "and create a new API token\n",
        "\n",
        "![Imgur](https://i.imgur.com/4MyzhNM.png)\n",
        "\n",
        "- Upload your API Info below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6OxeeQyS4qG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!echo \"Please upload your API info\"\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!echo \"Files Uploaded\"\n",
        "\n",
        "!echo \"Creating the kaggle folder\"\n",
        "!mkdir ~/.kaggle\n",
        "\n",
        "!echo \"Copying the api info to the main folder\"\n",
        "!cp /content/kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "%cd ~/.kaggle\n",
        "\n",
        "!echo \"Downloading the dataset\"\n",
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
        "\n",
        "!echo \"Unziping the dataset\"\n",
        "!unzip \\*.zip  && rm *.zip\n",
        "!echo \"Done.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg7L0agNs6XE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Flatten, Activation, MaxPooling2D, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QinxEFvkyJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Get_dataset(datatype):\n",
        "    # dataset directory\n",
        "    directory = os.path.join(\"/root/.kaggle/chest_xray/chest_xray\", datatype)\n",
        "\n",
        "    # pneumonia categories\n",
        "    categories = [\"NORMAL\", \"PNEUMONIA\"]\n",
        "\n",
        "    # initialize data list\n",
        "    data = []\n",
        "\n",
        "    # image width and height\n",
        "    image_size = 120\n",
        "\n",
        "    for category in categories:  \n",
        "\n",
        "        path = os.path.join(directory,category)  \n",
        "        class_num = categories.index(category)  \n",
        "\n",
        "        for img in tqdm(os.listdir(path)): \n",
        "            try:\n",
        "\n",
        "                #convert image to grayscale and then to an array\n",
        "                image_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE) \n",
        "              \n",
        "                # resize the image\n",
        "                resized_array = cv2.resize(image_array, (image_size, image_size))  \n",
        "                \n",
        "                # add image and its category to a a list\n",
        "                data.append([resized_array, class_num]) \n",
        "            \n",
        "            # just to keep the output clean\n",
        "            except Exception as e:\n",
        "                pass\n",
        "    \n",
        "    ##shuffle the data\n",
        "    random.shuffle(data)\n",
        "\n",
        "    # initialize the lists\n",
        "    images = []\n",
        "    labels = []    \n",
        "\n",
        "    ##split the data as train images and train_labels \n",
        "    for features,label in data:\n",
        "        images.append(features)\n",
        "        labels.append(label)\n",
        "\n",
        "    # reshape the arrays\n",
        "    images = np.array(images).reshape(-1, image_size, image_size, 1)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # normalize the data\n",
        "    images = images/255.0\n",
        "\n",
        "    return images, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPgyPu_f1JtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get train data\n",
        "train_images, train_labels = Get_dataset(\"train\")\n",
        "\n",
        "# get test data\n",
        "test_images, test_labels = Get_dataset(\"test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ng1OCkYjjZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creates a data generator object that transforms images\n",
        "datagen = ImageDataGenerator(\n",
        "  rotation_range=10,\n",
        "  width_shift_range=0.1,\n",
        "  height_shift_range=0.1,\n",
        "  zoom_range=0.1,\n",
        "  horizontal_flip=True\n",
        ")\n",
        "\n",
        "\n",
        "data_augmentation = datagen.flow(train_images, train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-128rGmk56N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of epochs\n",
        "EPOCHS = 10\n",
        "\n",
        "# optimizer\n",
        "OPTIMIZER = Adam(learning_rate=0.0001)\n",
        "\n",
        "# model type\n",
        "model = Sequential()\n",
        "\n",
        "# first convolutional and pooling layers\n",
        "model.add(Conv2D(32, (3, 3), input_shape=train_images.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# second convolutional and pooling layers\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# dense layers\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# dropout layer to prevent overfitting\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "# flatten the data\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "# callbacks\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss', \n",
        "    mode='min', \n",
        "    verbose=1, \n",
        "    patience=5\n",
        ")\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    '/content/model.h5',\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    verbose=1,\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "callbacks = [early_stopping, model_checkpoint]\n",
        "\n",
        "# compile the model\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=OPTIMIZER,\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# train the model\n",
        "history = model.fit(\n",
        "    data_augmentation,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data = (test_images, test_labels),\n",
        "    callbacks=callbacks\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tYnp2eTHp0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# visualizing losses and accuracy\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "train_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(EPOCHS), train_loss)\n",
        "plt.plot(range(EPOCHS), val_loss)\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs') \n",
        "plt.ylabel('Loss') \n",
        "plt.legend({'Test Data','Training Data'})\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(EPOCHS), train_acc)\n",
        "plt.plot(range(EPOCHS), val_acc)\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epochs') \n",
        "plt.ylabel('Accuracy') \n",
        "plt.legend({'Test Data','Training Data'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlOdV6iW88A-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predictions about totally new data\n",
        "pred_images, pred_labels = Get_dataset('val')\n",
        "\n",
        "predictions = model.predict(pred_images)\n",
        "\n",
        "for w in range(len(predictions)):\n",
        "  if pred_labels[w] <= 0.5:\n",
        "    print(\"\\nNORMAL:\", predictions[w])\n",
        "  else:\n",
        "    print(\"\\nPNEUMONIA:\", predictions[w])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}